{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_headline</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After Musk tweets 'Use Signal', unrelated stoc...</td>\n",
       "      <td>After Elon Musk endorsed encrypted messaging a...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump permanently banned from Twitter</td>\n",
       "      <td>Twitter has permanently banned US President Do...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man finds father's image on Google Earth 7 yea...</td>\n",
       "      <td>A man in Japan found an image of his father, w...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad sign: Mexican Prez after Trump's social me...</td>\n",
       "      <td>Following the suspension of US President Donal...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Signal app registration system crashes after M...</td>\n",
       "      <td>Private encrypted messaging app Signal tweeted...</td>\n",
       "      <td>technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       news_headline   \n",
       "0  After Musk tweets 'Use Signal', unrelated stoc...  \\\n",
       "1       Donald Trump permanently banned from Twitter   \n",
       "2  Man finds father's image on Google Earth 7 yea...   \n",
       "3  Bad sign: Mexican Prez after Trump's social me...   \n",
       "4  Signal app registration system crashes after M...   \n",
       "\n",
       "                                        news_article news_category  \n",
       "0  After Elon Musk endorsed encrypted messaging a...    technology  \n",
       "1  Twitter has permanently banned US President Do...    technology  \n",
       "2  A man in Japan found an image of his father, w...    technology  \n",
       "3  Following the suspension of US President Donal...    technology  \n",
       "4  Private encrypted messaging app Signal tweeted...    technology  "
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "while 'news_data' not in os.listdir():\n",
    "    os.chdir('..')\n",
    "\n",
    "file_names = [os.path.join('news_data', file_name) for file_name in os.listdir('news_data')]\n",
    "dfs = []\n",
    "for file_name in os.listdir('news_data'):\n",
    "    dfs.append(pd.read_csv(os.path.join('news_data', file_name), index_col = 0))\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_headline</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_category</th>\n",
       "      <th>joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After Musk tweets 'Use Signal', unrelated stoc...</td>\n",
       "      <td>After Elon Musk endorsed encrypted messaging a...</td>\n",
       "      <td>technology</td>\n",
       "      <td>After Musk tweets 'Use Signal', unrelated stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump permanently banned from Twitter</td>\n",
       "      <td>Twitter has permanently banned US President Do...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Donald Trump permanently banned from Twitter. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man finds father's image on Google Earth 7 yea...</td>\n",
       "      <td>A man in Japan found an image of his father, w...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Man finds father's image on Google Earth 7 yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad sign: Mexican Prez after Trump's social me...</td>\n",
       "      <td>Following the suspension of US President Donal...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Bad sign: Mexican Prez after Trump's social me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Signal app registration system crashes after M...</td>\n",
       "      <td>Private encrypted messaging app Signal tweeted...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Signal app registration system crashes after M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       news_headline   \n",
       "0  After Musk tweets 'Use Signal', unrelated stoc...  \\\n",
       "1       Donald Trump permanently banned from Twitter   \n",
       "2  Man finds father's image on Google Earth 7 yea...   \n",
       "3  Bad sign: Mexican Prez after Trump's social me...   \n",
       "4  Signal app registration system crashes after M...   \n",
       "\n",
       "                                        news_article news_category   \n",
       "0  After Elon Musk endorsed encrypted messaging a...    technology  \\\n",
       "1  Twitter has permanently banned US President Do...    technology   \n",
       "2  A man in Japan found an image of his father, w...    technology   \n",
       "3  Following the suspension of US President Donal...    technology   \n",
       "4  Private encrypted messaging app Signal tweeted...    technology   \n",
       "\n",
       "                                              joined  \n",
       "0  After Musk tweets 'Use Signal', unrelated stoc...  \n",
       "1  Donald Trump permanently banned from Twitter. ...  \n",
       "2  Man finds father's image on Google Earth 7 yea...  \n",
       "3  Bad sign: Mexican Prez after Trump's social me...  \n",
       "4  Signal app registration system crashes after M...  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['joined'] = df.apply(lambda row: row['news_headline'] + '. ' + row['news_article'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_headline</th>\n",
       "      <th>news_article</th>\n",
       "      <th>news_category</th>\n",
       "      <th>joined</th>\n",
       "      <th>news_category_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After Musk tweets 'Use Signal', unrelated stoc...</td>\n",
       "      <td>After Elon Musk endorsed encrypted messaging a...</td>\n",
       "      <td>technology</td>\n",
       "      <td>After Musk tweets 'Use Signal', unrelated stoc...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump permanently banned from Twitter</td>\n",
       "      <td>Twitter has permanently banned US President Do...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Donald Trump permanently banned from Twitter. ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Man finds father's image on Google Earth 7 yea...</td>\n",
       "      <td>A man in Japan found an image of his father, w...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Man finds father's image on Google Earth 7 yea...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad sign: Mexican Prez after Trump's social me...</td>\n",
       "      <td>Following the suspension of US President Donal...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Bad sign: Mexican Prez after Trump's social me...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Signal app registration system crashes after M...</td>\n",
       "      <td>Private encrypted messaging app Signal tweeted...</td>\n",
       "      <td>technology</td>\n",
       "      <td>Signal app registration system crashes after M...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       news_headline   \n",
       "0  After Musk tweets 'Use Signal', unrelated stoc...  \\\n",
       "1       Donald Trump permanently banned from Twitter   \n",
       "2  Man finds father's image on Google Earth 7 yea...   \n",
       "3  Bad sign: Mexican Prez after Trump's social me...   \n",
       "4  Signal app registration system crashes after M...   \n",
       "\n",
       "                                        news_article news_category   \n",
       "0  After Elon Musk endorsed encrypted messaging a...    technology  \\\n",
       "1  Twitter has permanently banned US President Do...    technology   \n",
       "2  A man in Japan found an image of his father, w...    technology   \n",
       "3  Following the suspension of US President Donal...    technology   \n",
       "4  Private encrypted messaging app Signal tweeted...    technology   \n",
       "\n",
       "                                              joined  news_category_num  \n",
       "0  After Musk tweets 'Use Signal', unrelated stoc...                  5  \n",
       "1  Donald Trump permanently banned from Twitter. ...                  5  \n",
       "2  Man finds father's image on Google Earth 7 yea...                  5  \n",
       "3  Bad sign: Mexican Prez after Trump's social me...                  5  \n",
       "4  Signal app registration system crashes after M...                  5  "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder().fit(np.unique(df['news_category']))\n",
    "labels_num = enc.transform(df['news_category'])\n",
    "\n",
    "df['news_category_num'] = labels_num\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split into train, val & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "df_shuffled = shuffle(df, random_state=0)\n",
    "\n",
    "def train_val_test_split(X, y, val_size=0.2, test_size=0.1):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=0)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, random_state=0)\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(df_shuffled[['news_headline', 'news_article', 'joined']], df_shuffled['news_category_num'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inicialization (without fine-tuning)\n",
    "\n",
    "Fine-tuning will be soon ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(task=\"zero-shot-classification\", model=\"valhalla/distilbart-mnli-12-1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference + testing\n",
    "\n",
    "Info before you run: inference of 1 sample on MacBook with M1, 8GB RAM takes around 3 seconds.\n",
    "\n",
    "Feel free to change the number of k_samples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "entertainment       0.50      1.00      0.67         1\n",
      "     politics       0.50      1.00      0.67         1\n",
      "      science       1.00      1.00      1.00         2\n",
      "       sports       1.00      1.00      1.00         1\n",
      "   technology       1.00      1.00      1.00         2\n",
      "        world       1.00      0.33      0.50         3\n",
      "\n",
      "     accuracy                           0.80        10\n",
      "    macro avg       0.83      0.89      0.81        10\n",
      " weighted avg       0.90      0.80      0.78        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "k_samples = 10\n",
    "\n",
    "# Here I'm using just news_article\n",
    "results = generator(sequences=list(X_test['news_article'][:k_samples]), candidate_labels = list(np.unique(df_shuffled['news_category'])))\n",
    "\n",
    "y_pred = [result['labels'][0] for result in results]\n",
    "y_true = y_test[:k_samples]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "entertainment       1.00      1.00      1.00         1\n",
      "     politics       1.00      1.00      1.00         1\n",
      "      science       1.00      1.00      1.00         2\n",
      "       sports       1.00      1.00      1.00         1\n",
      "   technology       1.00      0.50      0.67         2\n",
      "        world       0.75      1.00      0.86         3\n",
      "\n",
      "     accuracy                           0.90        10\n",
      "    macro avg       0.96      0.92      0.92        10\n",
      " weighted avg       0.93      0.90      0.89        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_test['headline_article'] = X_test.apply(lambda row: row['news_headline'] + '. ' + row['news_article'], axis = 1)\n",
    "\n",
    "k_samples = 10\n",
    "\n",
    "# Here I'm using just news_article\n",
    "results = generator(sequences=list(X_test['headline_article'][:k_samples]), candidate_labels = list(np.unique(df_shuffled['news_category'])))\n",
    "\n",
    "y_pred = [result['labels'][0] for result in results]\n",
    "y_true = y_test[:k_samples]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing + Model fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_dataset(X, y):\n",
    "\n",
    "    dataset = {\n",
    "        'label': torch.tensor(list(y)),\n",
    "        # 'text': torch.tensor(list(X))\n",
    "    }\n",
    "\n",
    "    dataset.update(tokenizer(list(X), padding=True, truncation=True, return_tensors=\"pt\"))\n",
    "\n",
    "    return Dataset.from_dict(dataset)\n",
    "\n",
    "train_dataset = hf_dataset(X_train['joined'], y_train)\n",
    "val_dataset = hf_dataset(X_val['joined'], y_val)\n",
    "test_dataset = hf_dataset(X_test['joined'], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 8726\n",
       "})"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=7)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset.select(range(100)),\n",
    "    eval_dataset=val_dataset.select(range(100)),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0dba86293449cfaddc5dbc2c88f5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e339f98baaa74021a21b5a9f3c93ca63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.753369152545929, 'eval_accuracy': 0.72, 'eval_runtime': 22.8713, 'eval_samples_per_second': 4.372, 'eval_steps_per_second': 0.568, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60be8320ab2b41759fc21a1fb221a079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.753369152545929, 'eval_accuracy': 0.72, 'eval_runtime': 22.5547, 'eval_samples_per_second': 4.434, 'eval_steps_per_second': 0.576, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34416fb55b5c439a8bafa6e80c3f27b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.753369152545929, 'eval_accuracy': 0.72, 'eval_runtime': 21.2766, 'eval_samples_per_second': 4.7, 'eval_steps_per_second': 0.611, 'epoch': 3.0}\n",
      "{'train_runtime': 342.8229, 'train_samples_per_second': 0.875, 'train_steps_per_second': 0.114, 'train_loss': 0.7753731165176783, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=0.7753731165176783, metrics={'train_runtime': 342.8229, 'train_samples_per_second': 0.875, 'train_steps_per_second': 0.114, 'train_loss': 0.7753731165176783, 'epoch': 3.0})"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and mini-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_dataset(X):\n",
    "\n",
    "    dataset = tokenizer(list(X), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       1.00      1.00      1.00         1\n",
      "           5       0.75      1.00      0.86         3\n",
      "           6       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           0.90        10\n",
      "   macro avg       0.79      0.83      0.81        10\n",
      "weighted avg       0.82      0.90      0.86        10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/deepsenseai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/deepsenseai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/miniconda3/envs/deepsenseai/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "k_samples = 10\n",
    " \n",
    "dict_test_dataset = inference_dataset(X_test['joined'][:k_samples])\n",
    "\n",
    "results = model(**dict_test_dataset).logits\n",
    "\n",
    "y_pred = [torch.argmax(result) for result in results]\n",
    "y_true = y_test[:k_samples]\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsenseai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
